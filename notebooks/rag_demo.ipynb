{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062808a8",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38a849bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece3617a",
   "metadata": {},
   "source": [
    "## Suppress warnings from MuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a58fd84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SuppressMuPDFWarnings:\n",
    "    def __enter__(self):\n",
    "        self._original_stderr = sys.stderr\n",
    "        sys.stderr = open(os.devnull, 'w')\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stderr.close()\n",
    "        sys.stderr = self._original_stderr\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197cbf9",
   "metadata": {},
   "source": [
    "## Define the RAGPipeline class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b15d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGPipeline:\n",
    "    def __init__(self, pdf_folder=PROJECT_ROOT / \"data\", embedding_model_path=PROJECT_ROOT / \"models\" / \"paraphrase-MiniLM-L6-v2\",\n",
    "                 llm_model_path=PROJECT_ROOT / \"models\" / \"falcon-rw-1b\", top_k=3):\n",
    "        self.pdf_folder = pdf_folder\n",
    "        self.top_k = top_k\n",
    "        self.embedder = SentenceTransformer(str(embedding_model_path), local_files_only=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(str(llm_model_path), local_files_only=True)\n",
    "        self.llm_model = AutoModelForCausalLM.from_pretrained(str(llm_model_path), local_files_only=True)\n",
    "        device = 0 if torch.cuda.is_available() else -1\n",
    "        self.generator = pipeline(\"text-generation\", model=self.llm_model, tokenizer=self.tokenizer, device=device)\n",
    "\n",
    "    def load_pdfs(self):\n",
    "        documents = []\n",
    "        for pdf_path in Path(self.pdf_folder).glob(\"*.pdf\"):\n",
    "            try:\n",
    "                with SuppressMuPDFWarnings():\n",
    "                    with fitz.open(pdf_path) as doc:\n",
    "                        text = \"\".join([page.get_text() for page in doc])\n",
    "                        if len(text.strip()) > 10:\n",
    "                            documents.append({\"filename\": pdf_path.name, \"content\": text})\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {pdf_path.name}: {e}\")\n",
    "        return documents\n",
    "\n",
    "    def chunk_text(self, text, max_tokens=200):\n",
    "        sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "        chunks, current_chunk = [], \"\"\n",
    "        for sentence in sentences:\n",
    "            if len(current_chunk.split()) + len(sentence.split()) < max_tokens:\n",
    "                current_chunk += \" \" + sentence\n",
    "            else:\n",
    "                chunks.append(current_chunk.strip())\n",
    "                current_chunk = sentence\n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk.strip())\n",
    "        return chunks\n",
    "\n",
    "    def embed_chunks(self, documents):\n",
    "        embedded_chunks = []\n",
    "        for doc in documents:\n",
    "            chunks = self.chunk_text(doc[\"content\"])\n",
    "            for chunk in chunks:\n",
    "                embedding = self.embedder.encode(chunk)\n",
    "                embedded_chunks.append({\n",
    "                    \"filename\": doc[\"filename\"],\n",
    "                    \"text\": chunk,\n",
    "                    \"embedding\": embedding\n",
    "                })\n",
    "        return embedded_chunks\n",
    "\n",
    "    def retrieve_relevant_chunks(self, question, embedded_chunks):\n",
    "        question_embedding = self.embedder.encode(question)\n",
    "        similarities = [\n",
    "            (cosine_similarity([question_embedding], [chunk[\"embedding\"]])[0][0], chunk)\n",
    "            for chunk in embedded_chunks\n",
    "        ]\n",
    "        sorted_chunks = sorted(similarities, key=lambda x: x[0], reverse=True)\n",
    "        return [chunk for _, chunk in sorted_chunks[:self.top_k]]\n",
    "\n",
    "    def generate_answer(self, question, retrieved_chunks):\n",
    "        context = \"\\n\".join([chunk[\"text\"] for chunk in retrieved_chunks])\n",
    "        prompt = (\n",
    "            f\"Use the following information to answer the instruction briefly and precisely.\\n\"\n",
    "            f\"Context:\\n{context}\\n\\nInstruction: {question}\\nAnswer:\"\n",
    "        )\n",
    "        response = self.generator(\n",
    "            prompt,\n",
    "            max_new_tokens=100,\n",
    "            do_sample=False,\n",
    "            pad_token_id=self.tokenizer.eos_token_id,\n",
    "            eos_token_id=self.tokenizer.eos_token_id,\n",
    "        )[0][\"generated_text\"]\n",
    "\n",
    "        answer_start = response.find(\"Answer:\")\n",
    "        answer = response[answer_start + len(\"Answer:\"):].strip() if answer_start != -1 else response.strip()\n",
    "\n",
    "        lines = answer.splitlines()\n",
    "        seen, unique_lines = set(), []\n",
    "        for line in lines:\n",
    "            clean_line = line.strip()\n",
    "            if clean_line and clean_line not in seen:\n",
    "                unique_lines.append(clean_line)\n",
    "                seen.add(clean_line)\n",
    "\n",
    "        return \" \".join(unique_lines)\n",
    "\n",
    "    def evaluate_answer(self, question, answer):\n",
    "        question_embedding = self.embedder.encode(question)\n",
    "        answer_embedding = self.embedder.encode(answer)\n",
    "        similarity = cosine_similarity([question_embedding], [answer_embedding])[0][0]\n",
    "        return similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c63a6d2",
   "metadata": {},
   "source": [
    "## Initialize the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef785893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "rag = RAGPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5057f493",
   "metadata": {},
   "source": [
    "## Load PDF documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e074ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "MuPDF error: library error: zlib error: incorrect header check\n",
      "\n",
      "Loaded 2 documents.\n"
     ]
    }
   ],
   "source": [
    "documents = rag.load_pdfs()\n",
    "print(f\"Loaded {len(documents)} documents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7804d",
   "metadata": {},
   "source": [
    "## Embed chunks from PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d10be144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 159 chunks.\n"
     ]
    }
   ],
   "source": [
    "embedded_chunks = rag.embed_chunks(documents)\n",
    "print(f\"Embedded {len(embedded_chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bf8358",
   "metadata": {},
   "source": [
    "## Ask a question and retrieve relevant chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "931eb78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      ".3\n",
      "Understanding the Cloud .......................................................... 5\n",
      "Scale and elasticity  ......................................................... 5\n",
      "Self-service provisioning ................................................. 6\n",
      "Using Web services interfaces ....................................... 6\n",
      "Billing and metering services ......................................... 7\n",
      "Monitoring and measuring performance ...................... 7\n",
      "Providing security to customers  ..............\n",
      "\n",
      "--- Chunk 2 ---\n",
      "If they’re inside \n",
      "IT, it has often been easier for them to get their work done. If they \n",
      "reside outside IT, it hasn’t always been ideal.\n",
      "Understanding their challenges\n",
      "We know developers care about speed in the context of how \n",
      "quickly they can get their creations to market and the quality of \n",
      "their applications. But as with anything, developers are keenly \n",
      "aware of the time–cost–risk triad. Simply put, the time–cost–risk \n",
      "triad means that you can only pick two of the three elements at a \n",
      "single...\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Chapter 5 is a list \n",
      "of the most important questions to ask when thinking about \n",
      "getting started with the cloud.\n",
      "Icons Used in This Book\n",
      "You may notice some icons in the margins of this book that \n",
      "point to certain types of information:\n",
      " \n",
      "This is a particularly useful point to pay attention to.\n",
      " \n",
      "Pay attention. This will save you time and trouble later.\n",
      " \n",
      "You may be sorry if this little tidbit slips your mind.\n",
      "These materials are the copyright of Wiley Publishing, Inc. and any  \n",
      "dissemination, di...\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the edge?\"\n",
    "relevant_chunks = rag.retrieve_relevant_chunks(question, embedded_chunks)\n",
    "for i, chunk in enumerate(relevant_chunks, 1):\n",
    "    print(f\"\\n--- Chunk {i} ---\\n{chunk['text'][:500]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637913e",
   "metadata": {},
   "source": [
    "## Generate an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a5b1603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "The edge is the physical location where the cloud services are delivered. ▶ Defining the cloud The cloud is a new way of delivering services. It’s a new way of delivering services that is infrastructure-as-a-service (IaaS), platform-as-a-service (PaaS), software-as-a-service (SaaS), and infrastructure-as-a-service (IaaS\n"
     ]
    }
   ],
   "source": [
    "answer = rag.generate_answer(question, relevant_chunks)\n",
    "print(f\"\\nAnswer:\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37083b1",
   "metadata": {},
   "source": [
    "## Evaluate the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "588f8143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Score: 0.53\n"
     ]
    }
   ],
   "source": [
    "similarity_score = rag.evaluate_answer(question, answer)\n",
    "print(f\"\\nSimilarity Score: {similarity_score:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
